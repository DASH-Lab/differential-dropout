{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import ResNet as resnet\n",
    "import DenseNet as densenet\n",
    "import EfficientNet as efficientnet\n",
    "import MobileNetV2 as mobilenet\n",
    "import ViT as vit\n",
    "import solver.solver as solver\n",
    "import solver.solver_v2 as solver_v2\n",
    "import solver.solver_v3 as solver_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "diff_drop = \"v0\"\n",
    "\n",
    "model = vit.ViT(num_classes=8, diff_drop=diff_drop).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/media/data2/data/CelebAMask-HQ/CelebA-HQ-img/\"\n",
    "annotation_path = \"/media/data2/data/CelebAMask-HQ/CelebAMask-HQ-attribute-anno.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebA(Dataset):\n",
    "    def __init__(self, root, annotation_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.root_dir = root\n",
    "        self.classes = [\n",
    "            \"Female, Not smiling, Young\", \"Female, Not smiling, Old\", \n",
    "            \"Female, Smiling, Young\", \"Female, Smiling, Old\", \n",
    "            \"Male, Not smiling, Young\", \"Male, Not smiling, Old\", \n",
    "            \"Male, Smiling, Young\", \"Male, Smiling, Old\",\n",
    "        ]\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.image_labels = []\n",
    "\n",
    "        anno_file = open(annotation_path, \"r\")\n",
    "        num = int(anno_file.readline())\n",
    "    \n",
    "        line = anno_file.readline()\n",
    "        attributes = list(line[:-1].split(' '))\n",
    "        \n",
    "        sex_index = attributes.index('Male') + 2\n",
    "        smile_index = attributes.index('Smiling') + 2\n",
    "        young_index = attributes.index('Young') + 2\n",
    "        for _ in range(num):\n",
    "            line = anno_file.readline()\n",
    "            record = list(line[:-1].split(' '))\n",
    "            self.image_paths.append(record[0])\n",
    "            if record[sex_index] == \"1\":\n",
    "                if record[smile_index] == \"1\":\n",
    "                    if record[young_index] == \"1\":\n",
    "                        self.image_labels.append(6)\n",
    "                    else:\n",
    "                        self.image_labels.append(7)\n",
    "                else:\n",
    "                    if record[young_index] == \"1\":\n",
    "                        self.image_labels.append(4)\n",
    "                    else:\n",
    "                        self.image_labels.append(5)\n",
    "            else:\n",
    "                if record[smile_index] == \"1\":\n",
    "                    if record[young_index] == \"1\":\n",
    "                        self.image_labels.append(2)\n",
    "                    else:\n",
    "                        self.image_labels.append(3)\n",
    "                else:\n",
    "                    if record[young_index] == \"1\":\n",
    "                        self.image_labels.append(0)\n",
    "                    else:\n",
    "                        self.image_labels.append(1)\n",
    "        anno_file.close()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_file_path = os.path.join(self.root_dir, self.image_paths[index])\n",
    "        image = Image.open(image_file_path)\n",
    "\n",
    "        label = self.image_labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female, Not smiling, Young', 'Female, Not smiling, Old', 'Female, Smiling, Young', 'Female, Smiling, Old', 'Male, Not smiling, Young', 'Male, Not smiling, Old', 'Male, Smiling, Young', 'Male, Smiling, Old']\n",
      "21000 9000 30000\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "celebAset = CelebA(root=dataset_path, annotation_path=annotation_path, transform=trans)\n",
    "train_size = int(0.7 * len(celebAset))\n",
    "trainset, testset = random_split(celebAset, [train_size, len(celebAset) - train_size])\n",
    "\n",
    "train_loader = DataLoader(celebAset, batch_size=batch_size, shuffle=True, drop_last=False, )\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, drop_last=False, )\n",
    "\n",
    "classes = celebAset.classes\n",
    "print(classes)\n",
    "print(len(trainset), len(testset), len(celebAset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        \n",
    "        pred = None\n",
    "        p = 0.0\n",
    "        if diff_drop == \"v3\":\n",
    "            pred, p = model(X.to(device), epoch)\n",
    "        else:\n",
    "            pred, p = model(X.to(device))\n",
    "        \n",
    "        loss = criterion(pred, y.to(device))\n",
    "        correct += (torch.argmax(pred, dim=1) == y.to(device)).type(torch.float).sum().item()\n",
    "        total_correct += correct\n",
    "        \n",
    "        model.train()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        if diff_drop == \"v1\":\n",
    "            solver.PseudoPruning(model.classification_head.fc, p)\n",
    "        elif diff_drop == \"v2\":\n",
    "            solver_v2.PseudoPruning(model.classification_head.fc, p)\n",
    "        elif diff_drop == \"v3\":\n",
    "            solver_v3.PseudoPruning(model.classification_head.fc, p)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch % 50 == 0):\n",
    "            print(f\"Batch {batch:>5d}: Loss per batch is {loss.item():>7.6f} and Accuracy is {correct / batch_size:>7.6f}\")\n",
    "    print(f\"For Iteration: Loss is {(total_loss / (size // batch_size)):>7.6f} and Accuracy is {total_correct / size:>7.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, criterion):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred, _ = model(X.to(device))\n",
    "            test_loss += criterion(pred, y.to(device)).item()\n",
    "            \n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            correct += (pred == y.to(device)).type(torch.float).sum().item()\n",
    "            \n",
    "            pred = pred.cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            y_true.extend(y)\n",
    "            y_pred.extend(pred)\n",
    "    \n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, target_names=classes))\n",
    "    \n",
    "    return correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch 1 ------------------\n",
      "Batch     0: Loss per batch is 2.510577 and Accuracy is 0.093750\n"
     ]
    }
   ],
   "source": [
    "max = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Training: Epoch {epoch + 1} ------------------\")\n",
    "    train_loop(train_loader, model, criterion, optimizer, epoch + 1)\n",
    "    print(f\"----Test: Epoch {epoch + 1} ------------------\")\n",
    "    temp = test_loop(test_loader, model, criterion)\n",
    "    \n",
    "    # if temp > max:\n",
    "    #     max = temp\n",
    "    #     torch.save(model, './celebAHQ_split_effib0_v3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './celebAHQ_all_vit_nothing.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
