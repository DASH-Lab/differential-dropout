{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import models.ResNet as resnet\n",
    "import models.DenseNet as densenet\n",
    "import models.EfficientNet as efficientnet\n",
    "import models.MobileNetV2 as mobilenet\n",
    "import models.ViT as vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.25\n",
    "\n",
    "model = resnet.resnet50(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/media/data1/hyunjun/cifar-10/train/\"\n",
    "test_path = \"/media/data1/hyunjun/cifar-10/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262)),\n",
    "    transforms.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_path, transform=trans)\n",
    "testset = torchvision.datasets.ImageFolder(root=test_path, transform=trans)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=False, )\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, drop_last=False, )\n",
    "\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        correct = 0\n",
    "        \n",
    "        pred = model(X.to(device))\n",
    "        loss = criterion(pred, y.to(device))\n",
    "        correct += (torch.argmax(pred, dim=1) == y.to(device)).type(torch.float).sum().item()\n",
    "        total_correct += correct\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if (batch % 50 == 0):\n",
    "        #     print(f\"Batch {batch:>5d}: Loss per batch is {loss.item():>7.6f} and Accuracy is {correct / batch_size:>7.6f}\")\n",
    "    print(f\"For Iteration: Loss is {(total_loss / (size // batch_size)):>7.6f} and Accuracy is {total_correct / size:>7.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, criterion):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            test_loss += criterion(pred, y.to(device)).item()\n",
    "            \n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            correct += (pred == y.to(device)).type(torch.float).sum().item()\n",
    "            \n",
    "            pred = pred.cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            y_true.extend(y)\n",
    "            y_pred.extend(pred)\n",
    "    \n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, target_names=classes))\n",
    "    \n",
    "    return correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Training: Epoch {epoch + 1} ------------------\")\n",
    "    train_loop(train_loader, model, criterion, optimizer)\n",
    "    print(f\"----Test: Epoch {epoch + 1} ------------------\")\n",
    "    temp = test_loop(test_loader, model, criterion)\n",
    "    \n",
    "    if temp > max:\n",
    "        max = temp\n",
    "        #torch.save(model, './model_cifar10.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
